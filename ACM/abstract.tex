\documentclass[sigconf,screen]{acmart}

\title{Improving Code Completion in Pharo\\Using N-gram Language Models}
\author{Myroslava Romaniuk}
\affiliation{\institution{Ukrainian Catholic University}}
\email{romaniuk@ucu.edu.ua}

%%% The following is specific to <Programming'20> Companion-SRC and the paper
%%% 'Improving Code Completion in Pharo using N-gram Language Models'
%%% by Myroslava Romaniuk.
%%%
\setcopyright{acmcopyright}
\acmPrice{15.00}
\acmDOI{10.1145/3397537.3398483}
\acmYear{2020}
\copyrightyear{2020}
\acmSubmissionID{prog20src-p8-p}
\acmISBN{978-1-4503-7507-8/20/03}
\acmConference[<Programming'20> Companion]{Companion Proceedings of the 4th International Conference on the Art, Science, and Engineering of Programming}{March 23--26, 2020}{Porto, Portugal}
\acmBooktitle{Companion Proceedings of the 4th International Conference on the Art, Science, and Engineering of Programming (<Programming'20> Companion), March 23--26, 2020, Porto, Portugal}

\begin{document}
\begin{abstract}
In this paper I present applying statistical language models to improve code completion in Pharo\footnote{\url{https://pharo.org/}}. In particular, the goal is to use n-gram models for sorting the completion candidates and in such a way increase the relevancy of the suggested completions.

\section{Introduction}
Code completion is one of the most essential features in any IDE; it is one of the first things a developer notices and it is something that can "make or break" the flow of productivity when coding. The accuracy and the speed with which the completions are suggested are paramount in helping make the completion as effective as possible. That is why researchers and software engineers are constantly trying to find ways to enhance completion engines in IDEs.

When it comes to code completion in the Pharo IDE\footnote{Pharo is an object-oriented dynamically typed programming language inspired by Smalltalk, and the Pharo IDE is an interactive IDE intended for developing in Pharo.}, the situation is no different: over the past couple of years a lot of work has already been done to improve the completion engine there. However, I believe that it can only benefit from additionally improving the sorting strategies by using machine learning techniques.

\section{Context}
The current implementation of code completion in the Pharo IDE is based on abstract syntax tree (AST) information of source code, where we are able to determine the structure of the code and infer the type information where possible. We can then give contextually suitable completions, such as suggesting a class name for a global node, method names for a method node, and so on. However, once we get the list of suggestions, there is no efficient way to sort them, and so the desired completions can appear at the bottom of the list. This requires the developer to scroll down or type in more symbols and can be very unproductive.

In this work I intend to study how code completion in Pharo can be improved using statistical language models. In particular, the idea is to use the n-gram model, as it has been documented to be used for such a task \cite{Hind12a}, and, if successfully adapted to Pharo, I believe it can help enhance the quality of code completion.

\section{Related Works}
There are many approaches to handling the process of completing code. The classic strategies used to rely on language-specific pattern matching, i.e. completing based on the prefix the developer has typed in. According to Bruch et al. \cite{Bruc09a}, code completion engines up until 10 years ago would also mainly rely on type information, with no contextual analysis. In the paper, the authors countered this approach by implementing intelligent code completion systems, which learned from source code examples and gave much more contextually relevant results. In the latest years statistical and machine learning models have also gained popularity. In machine learning approaches, source code is often treated as regular text, and the contextual analysis is disregarded. IntelliSense\footnote{\url{https://code.visualstudio.com/docs/editor/intellisense}} is an example of a code completion tool that uses semantic analysis, whereas TabNine\footnote{\url{https://www.tabnine.com/}} is an example of a tool using deep learning.

This work has been inspired by the paper "On The Naturalness of Software" \cite{Hind12a}. There, as well as in \cite{Tu14a,Rayc14a,Hell17a,Li17a}, the structural information is not taken into consideration and the problem of improving code completion is reduced to a natural language processing problem, where predicting the next token is treated as predicting the next word in a sentence.

The n-gram language model approach proposed by Hindle et al. \cite{Hind12a} is based on capturing statistical regularity at the n-gram level by taking n-1 previous tokens that are already entered into the text buffer, and attempting to guess the next token. Using this model, it is possible to estimate the most probable sequences of tokens and suggest the most relevant code completions to developers.

\section{Proposed Approach}
\subsection{Implementation}
What we want to do in Pharo is slightly different. Unlike the implementations of \cite{Tu14a,Hind12a,Rayc14a,Hell17a,Li17a}, where code completion is based solely on the results of statistical or machine learning models, the code completion in Pharo works by making use of AST information and giving contextually relevant results. However, as Pharo is a dynamically-typed language, type information is not always available, and the suggested results, after being sorted alphabetically, require more effort to go through and manually narrow down. This is where we think a sorting strategy based on an n-gram model will work better. In this case tokens will be suggested according to their probability of appearing in the already typed sequence, which will allow us to propose more accurate suggestions even without knowing the exact type of the token.

The estimated contributions of this work are the following:
\begin{itemize}
  \item improve code completion in Pharo by sorting candidate completions with an n-gram language model
  \item build a tool based on a trained n-gram model that would propose completion fast enough to be used in an IDE
\end{itemize}

\subsection{Evaluation}

\section{Future Work}
We would like to have a methodology to numerically evaluate the results of code completion produced by different completion strategies. In particular, to have a robust estimation of the improvement of various n-gram models compared to the alphabetical completion sorting and among each other.

\section{Conclusion}
In this paper we proposed applying n-gram language models when sorting completion candidates in Pharo. Having an AST-based completion engine, we are not always able to infer type information from the nodes, and hope to compensate for it and improve the relevance of suggestions by implementing a fast n-gram based sorting functionality to be used in the Pharo IDE.

\end{abstract}
\maketitle
\bibliographystyle{ACM-Reference-Format}
\bibliography{rmod,others}
\end{document}